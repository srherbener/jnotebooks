{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes, 2/8/18\n",
    "\n",
    "## netCDF4 and HDF5\n",
    "\n",
    "* Netcdf4 and HDF5 both have the same underlying file structure\n",
    "    * File structure is called HDF5\n",
    "* Python Netcdf4\n",
    "    * Lots of unlimited size dimensions needs careful attention\n",
    "        * If more than one unlimited dimension, the default chunk size is 1024\n",
    "            * If this dimension ends up with small size, still have a size of 1024 allocated in the file\n",
    "            * Lots of wasted file space\n",
    "        * Unlimited dimensions appear to be detrimental to file size\n",
    "            * Large reduction in file size can be obtained by minimizing the number of unlimited dimensions\n",
    "        * Variable compression (zlib=True) slows way down with multiple unlimited dimensions\n",
    "        * These effects are likely coming from the need to keep rebuilding the variable as the dimension sizes keep changing\n",
    "            * The data has to be uncompressed and then re-compressed\n",
    "            * The gross mismatch of chunk sizes likely exacerbates this\n",
    "                * Both for performance and memory usage\n",
    "    * Example from jedi_bufr2nc\n",
    "        * jedi_bufr2nc.py Aircraft ../bufr2nc/test/data/gdas.t00z.prepbufr.nr aircraft.test.nc\n",
    "        * The input prepbufr file is 49MB\n",
    "        * When compression (level = 6) was used in jed_bufr2nc.py\n",
    "            * Default chunk sizing\n",
    "            * Process took about 20 minutes to run!\n",
    "            * Output file was about 100MB!\n",
    "            * A variable with size (1867,1) was using chunk size (1024,1024)\n",
    "        * Shut off compression (zlib=False)\n",
    "            * Process much faster --> 2 minutes\n",
    "            * But output file huge, 1GB!\n",
    "                * Ridiculous waste, the output data uncompressed should be around 350KB\n",
    "        * Specified chunksize using a size of 1 for all unlimited dimensions\n",
    "            * Runtime about the same\n",
    "            * File size reduced to 86MB\n",
    "                * Way better, but still excessive waste\n",
    "        * Used nccopy for two more improvements\n",
    "            * Change unlimited dims to fixed dims\n",
    "                * nccopy -u infile outfile\n",
    "            * Shuffle and compress file (level 6)\n",
    "                * nccopy -d 6 -s infile outfile\n",
    "            * Recommended to do these in two distict steps\n",
    "                * compression works much more effectively when dims are fixed\n",
    "        * Change unlimited dims to fixed dims\n",
    "            * Long runtime: 5 - 10 minutes\n",
    "            * File reduced to 6MB\n",
    "            * Note: no compress has been applied at this point\n",
    "        * Shuffle and compress file\n",
    "            * Very fast, 1 second\n",
    "            * File reduce to 211KB\n",
    "                * Much more reasonable\n",
    "        * Summary of impacts show in sequence the actions were tried\n",
    "        \n",
    "| Action | File Size | Var Size | Chunk Size |\n",
    "|:-------|:---------:|:--------:|:----------:|\n",
    "|Default chunking|1GB|(1867,1)|(1024,1024)|\n",
    "|Chunking with size 1 for unlim dims|86MB|(1867,1)|(1,1)|\n",
    "|Change unlim dims to fixed dims|6MB|(1867,1)|(1867,1)|\n",
    "|Shuffle and compress|221KB|(1861,1)|(1861,1)|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes, 2/9/18\n",
    "\n",
    "## jedi_bufr2nc.py\n",
    "\n",
    "* Cannot directly query the BUFR file (nor BUFR table) to find dimension sizes\n",
    "* Options for efficiently writing the netCDF file\n",
    "    * Two passes through the BUFR file\n",
    "        * Pass1: read all obs and determine dimension sizes\n",
    "            * Won't work to read a representative obs since number of levels can be different (T vs U example)\n",
    "        * Pass2: read obs and transfer to the netcdf file\n",
    "        \n",
    "        * Pros:\n",
    "            * Will get dimension sizes set to the minimum necessary per file\n",
    "            * Can make all netcdf dimensions fixed size\n",
    "            \n",
    "        * Cons:\n",
    "            * Slow to read the BUFR file twice (but not that bad)\n",
    "            \n",
    "    * One pass through the BUFR file and post process the netCDF file\n",
    "        * Create file uncompressed and unlimited dimensions while reading the BUFR file\n",
    "        * Convert dims to fixed\n",
    "        * Compress\n",
    "        \n",
    "        * Pros: \n",
    "            * Save time by only reading BUFR file once\n",
    "            * Compression may be optimized since the variables are complete before compression starts\n",
    "                * May not make much difference\n",
    "        \n",
    "        * Cons:\n",
    "            * Slow\n",
    "                * The \"convert dims to fixed\" is an especially slow process\n",
    "\n",
    "    * One pass through the BUFR file and assume max dimensions for the netCDF file\n",
    "        * Pros:\n",
    "            * Fastest execution\n",
    "        \n",
    "        * Cons:\n",
    "            * Wastes space\n",
    "                * Compression may mitigate this since there will be a lot of repeated values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes, 2/12/18\n",
    "\n",
    "## jedi_bufr2nc.py\n",
    "\n",
    "* Created srherbener/bufr2nc repository on GitHub\n",
    "    * jedi_bufr2nc.py script\n",
    "    * Two Fortran utilities\n",
    "        * pb_decode.f90: dump out bufr table and obs (ufbint() calls)\n",
    "        * pb_decode_events.f90: dump out bufr table and events (ufbevn() calls)\n",
    "* Test case: gdas.t00z.prepbufr.nr\n",
    "    * Runs in about 30 seconds\n",
    "    * Input 49MB\n",
    "    * Output (AIRCFT, AIRCAR) 200KB\n",
    "        * 18 messages selected\n",
    "        * 1867 obs recorded\n",
    "* Xin's file: prepbufr.gdas.20160304.t06z.nr.48h\n",
    "    * Runs in 1.5 hours\n",
    "    * Input 62MB\n",
    "    * Output (AIRCFT, AIRCAR) 4.3MB\n",
    "        * 2268 messages selected\n",
    "        * 222316 obs recorded\n",
    "* Performance is not good, the Fortran programs run a little faster considering the python script makes two passes through the BUFR file.\n",
    "    * Reading obs from a subset is slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes, 2/20/18\n",
    "\n",
    "* I'll be gatekeeper for the IODA repository\n",
    "\n",
    "* Map containing which list of mnemonics from BUFR go with each obs type should be placed in IODA somewhere\n",
    "    * One copy\n",
    "    * All subsystems have access to the list\n",
    "\n",
    "* Xin\n",
    "    * Variable names are hard coded in the netCDF readers\n",
    "    * src/ncdiag\n",
    "        * m_diag_aircraft.f90 (aircraft)\n",
    "        * m_diag_conv.f90 (conventional)\n",
    "        * m_diag_raob.f90 (radiosonde)\n",
    "    * Don't want to have to write separate fortran files for each obs type since there will be 30-40 of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notes, 2/26/18\n",
    "\n",
    "* GeoVaLs\n",
    "    * Column (vertical profile) of model data interpolated to obs location\n",
    "    * Don't differentiate time points yet\n",
    "        * This will need to be added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ncdiag format, 3/12/18\n",
    "\n",
    "## ioda/src/ncdiag/\n",
    "\n",
    "* Fortran structures defined in files for different obs types\n",
    "    * m_diag_conv.f90: conventional obs (radiosonde)\n",
    "    * m_diag_raob.f90: radiance obs\n",
    "    * m_diag_aircft.f90: aircraft obs\n",
    "\n",
    "* Each structure has the same three sections in them\n",
    "    * header\n",
    "    * mass (t,p,q)\n",
    "    * wind (u,v)\n",
    "\n",
    "* Elements of header section\n",
    "    * ObsType\n",
    "    * n_ObsType\n",
    "    * n_Observations\n",
    "    * n_Observations_Mass\n",
    "    * n_Observations_Wind\n",
    "    * n_Observations_Total\n",
    "    * date\n",
    "\n",
    "* Elements of mass section\n",
    "    * Station_ID\n",
    "    * Observation_Class\n",
    "    * Observation_Type\n",
    "    * Observation_Subtype\n",
    "    * Latitude\n",
    "    * Longitude\n",
    "    * Pressure\n",
    "    * Height\n",
    "    * Time\n",
    "    * Prep_QC_Mark\n",
    "    * Setup_QC_Mark\n",
    "    * Prep_Use_flag\n",
    "    * Analysis_Use_Flag\n",
    "    * Nonlinear_QC_Rel_Wgt\n",
    "    * Errinv_Input\n",
    "    * Errinv_Adjust\n",
    "    * Errinv_Final\n",
    "    * Observation\n",
    "    * Observation_Forecast_adjusted\n",
    "    * Observation_Forecast_unadjusted\n",
    "\n",
    "* Elements of wind section (same as mass except for elements near end are exapanded for u and v)\n",
    "    * Station_ID\n",
    "    * Observation_Class\n",
    "    * Observation_Type\n",
    "    * Observation_Subtype\n",
    "    * Latitude\n",
    "    * Longitude\n",
    "    * Pressure\n",
    "    * Height\n",
    "    * Time\n",
    "    * Prep_QC_Mark\n",
    "    * Setup_QC_Mark\n",
    "    * Prep_Use_flag\n",
    "    * Analysis_Use_Flag\n",
    "    * Nonlinear_QC_Rel_Wgt\n",
    "    * Errinv_Input\n",
    "    * Errinv_Adjust\n",
    "    * Errinv_Final\n",
    "    * u_Observation\n",
    "    * u_Observation_Forecast_adjusted\n",
    "    * u_Observation_Forecast_unadjusted\n",
    "    * v_Observation\n",
    "    * v_Observation_Forecast_adjusted\n",
    "    * v_Observation_Forecast_unadjusted\n",
    "    * Wind_Reduction_Factor_at_10m\n",
    "\n",
    "* Arrays of these structures get loaded up, then written out into netCDF files.\n",
    "    * Buffering is handled by the ncdiag code\n",
    "        * Load up a bunch of obs, then write out every once in a while\n",
    "\n",
    "## Dump of the header of a sample ncdiag file\n",
    "\n",
    "~~~~~~~~~\n",
    "8-33:bufr2nc.test stephenh$ ncdump -h ~/projects/data/ncdiag/diag_conv_t_ges.2016010900_control.nc4\n",
    "netcdf diag_conv_t_ges.2016010900_control {\n",
    "dimensions:\n",
    "\tnobs = UNLIMITED ; // (201763 currently)\n",
    "\tStation_ID_maxstrlen = 8 ;\n",
    "\tObservation_Class_maxstrlen = 7 ;\n",
    "\tBias_Correction_Terms_arr_dim = 3 ;\n",
    "variables:\n",
    "\tchar Station_ID(nobs, Station_ID_maxstrlen) ;\n",
    "\tchar Observation_Class(nobs, Observation_Class_maxstrlen) ;\n",
    "\tint Observation_Type(nobs) ;\n",
    "\tfloat Latitude(nobs) ;\n",
    "\tfloat Longitude(nobs) ;\n",
    "\tfloat Station_Elevation(nobs) ;\n",
    "\tfloat Pressure(nobs) ;\n",
    "\tfloat Height(nobs) ;\n",
    "\tfloat Time(nobs) ;\n",
    "\tfloat Prep_QC_Mark(nobs) ;\n",
    "\tfloat Setup_QC_Mark(nobs) ;\n",
    "\tfloat Prep_Use_Flag(nobs) ;\n",
    "\tfloat Analysis_Use_Flag(nobs) ;\n",
    "\tfloat Nonlinear_QC_Rel_Wgt(nobs) ;\n",
    "\tfloat Errinv_Input(nobs) ;\n",
    "\tfloat Errinv_Adjust(nobs) ;\n",
    "\tfloat Errinv_Final(nobs) ;\n",
    "\tfloat Observation(nobs) ;\n",
    "\tfloat Obs_Minus_Forecast_adjusted(nobs) ;\n",
    "\tfloat Obs_Minus_Forecast_unadjusted(nobs) ;\n",
    "\tfloat Data_Pof(nobs) ;\n",
    "\tfloat Bias_Correction_Terms(nobs, Bias_Correction_Terms_arr_dim) ;\n",
    "\n",
    "// global attributes:\n",
    "\t\t:Number_of_Predictors = 3 ;\n",
    "\t\t:date_time = 2016010900 ;\n",
    "\t\t:Number_of_state_vars = 579 ;\n",
    "}\n",
    "8-33:bufr2nc.test stephenh$\n",
    "~~~~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Meeting with Clara, 5/13/18\n",
    "\n",
    "* Clara is creating a new Fortran program called something like \"read_ncdiag.f90\" that will go in the GSI code.\n",
    "    * Mimics the function of read_prepbufr.f90, but reads ncdiag instead of prepbufr.\n",
    "\n",
    "## GSI, read_prepbufr.f90\n",
    "\n",
    "### Utilizes:\n",
    "* ufbint()\n",
    "    * Read a non-replicated or delayed-replicated data value\n",
    "* ufbevn()\n",
    "    * Read a nested replication sequence in the current subset\n",
    "    * The inner replication typically are levels\n",
    "    * The outer replication typically are events\n",
    "* ufbrep()\n",
    "    * Read regularly replicated data values\n",
    "* ufbqcd()\n",
    "    * Specialized read of nmemonic in current subset\n",
    "    * QCD -> Quality Control for table D entries\n",
    "        * NCEP specified codes, for marking prepBUFR processing steps\n",
    "    * FXY code where F = 3 and X = 63 (ie, 363YYY)\n",
    "        * Eg, 363008 (Y=008) is VIRTMP\n",
    "\n",
    "### Defines strings that are used for calling ufb\\* routines\n",
    "~~~~~~~~~\n",
    "!  data statements\n",
    "  data hdstr  /'SID XOB YOB DHR TYP ELV SAID T29'/\n",
    "  data hdstr2 /'TYP SAID T29 SID'/\n",
    "  data obstr  /'POB QOB TOB ZOB UOB VOB PWO MXGS HOVI CAT PRSS TDO PMO' /\n",
    "  data drift  /'XDR YDR HRDR                    '/\n",
    "  data sststr /'MSST DBSS SST1 SSTQM SSTOE           '/\n",
    "  data qcstr  /'PQM QQM TQM ZQM WQM NUL PWQ PMQ'/\n",
    "  data oestr  /'POE QOE TOE NUL WOE NUL PWE     '/\n",
    "! data satqcstr  /'RFFL QIFY QIFN EEQF'/\n",
    "  data satqcstr  /'QIFN'/\n",
    "  data prvstr /'PRVSTG'/   \n",
    "  data sprvstr /'SPRVSTG'/ \n",
    "  data levstr  /'POB'/\n",
    "  data cld2seqstr /'TOCC HBLCS'/      ! total cloud cover and height above surface of base of lowest cloud seen\n",
    "  data cldseqstr /'VSSO CLAM HOCB'/   ! vertical significance, cloud amount and cloud base height\n",
    "  data metarcldstr /'CLAM HOCB'/      ! cloud amount and cloud base height\n",
    "  data metarwthstr /'PRWE'/           ! present weather\n",
    "  data metarvisstr /'HOVI TDO'/       ! visibility and dew point\n",
    "  data goescldstr /'CDTP TOCC GCDTT CDTP_QM'/   ! NESDIS cloud products: cloud top pressure, total cloud amount,\n",
    "                                                !   cloud top temperature, cloud top temp. qc mark\n",
    "  data aircraftstr /'POAF IALR'/      ! phase of aircraft flight and vertical velocity\n",
    "  data maxtmintstr  /'MXTM MITM'/\n",
    "  data owavestr  /'HOWV'/\n",
    "  data cldceilhstr /'CEILING'/\n",
    "~~~~~~~~~\n",
    "\n",
    "### ufbint() calls:\n",
    "\n",
    "~~~~~~~~~\n",
    "ufbint(lunin,aircraftwk,2,255,levs,aircraftstr)\n",
    "ufbint(lunin,cldceilh,1,255,levs,cldceilhstr)\n",
    "ufbint(lunin,cldseq,3,10,cldseqlevs,cldseqstr)\n",
    "ufbint(lunin,drfdat,8,255,iret,drift)\n",
    "ufbint(lunin,fcstdat,3,255,levs,'UFC VFC TFC ')\n",
    "ufbint(lunin,goescld,4,1,levs,goescldstr)\n",
    "ufbint(lunin,hdr,1,1,iret,'ACID')\n",
    "ufbint(lunin,hdr,4,1,iret,hdstr2)\n",
    "ufbint(lunin,hdr,8,1,iret,hdstr)\n",
    "ufbint(lunin,hdr3,3,255,levs,'XDR YDR HRDR')\n",
    "ufbint(lunin,hdrtsb,1,1,iret,'TSB')\n",
    "ufbint(lunin,levdat,1,255,levs,levstr)\n",
    "ufbint(lunin,maxtmint,2,255,levs,maxtmintstr)\n",
    "ufbint(lunin,metarcld,2,10,metarcldlevs,metarcldstr)\n",
    "ufbint(lunin,metarvis,2,1,iret,metarvisstr)\n",
    "ufbint(lunin,metarwth,1,10,metarwthlevs,metarwthstr)\n",
    "ufbint(lunin,obsdat,13,255,levs,obstr)\n",
    "ufbint(lunin,obserr,8,255,levs,oestr)\n",
    "ufbint(lunin,owave,1,255,levs,owavestr)\n",
    "ufbint(lunin,qcmark,8,255,levs,qcstr)\n",
    "ufbint(lunin,r_prvstg,1,1,iret,prvstr)\n",
    "ufbint(lunin,r_sprvstg,1,1,iret,sprvstr)\n",
    "ufbint(lunin,satqc,1,1,iret,satqcstr)\n",
    "ufbint(lunin,sstdat,8,1,levs,sststr)\n",
    "~~~~~~~~~\n",
    "\n",
    "### ufbevn() calls:\n",
    "\n",
    "~~~~~~~~\n",
    "ufbevn(lunin,tobaux,2,255,20,levs,'TOB TQM')\n",
    "ufbevn(lunin,tpc,1,255,20,levs,'TPC')\n",
    "~~~~~~~~\n",
    "\n",
    "### ufbrep() calls:\n",
    "\n",
    "~~~~~~~~\n",
    "ufbrep(lunin,cld2seq,2,1,cld2seqlevs,cld2seqstr)\n",
    "~~~~~~~~\n",
    "\n",
    "### ufbqcd() calls:\n",
    "\n",
    "~~~~~~~~\n",
    "ufbqcd(lunin,'VIRTMP',vtcd)\n",
    "~~~~~~~~\n",
    "\n",
    "### General idea\n",
    "\n",
    "* The bufr2nc.py script needs to support the creation of the same sets of data that GSI read_prepbufr.f90 is handling\n",
    "* Since read_ncdiag.f90 is mimicing read_prepbufr.f90, the bufr2nc.py script needs to use the same mnemonic strings\n",
    "* It would be useful for both bufr2nc.py and read_ncdiag.f90 to read a single config file that defines the mnemonic strings\n",
    "    * Use Fortran namelist format\n",
    "        * Fortran can read directly\n",
    "        * Python has a namelist reader\n",
    "* Don't use nan for missing float (Clara has script changes)\n",
    "* Leave empty values in the ncdiag file for now\n",
    "    * Define 255 levels, only use 100 levels, leave the unused levels empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
